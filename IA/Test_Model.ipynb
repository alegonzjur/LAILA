{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Archivosdelprograma\\Environments\\lyrics_gen\\lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible: True\n",
      "Dispositivo actual: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Comprobar funcionamiento de CUDA.\n",
    "torch.cuda.empty_cache()\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
    "print(\"Dispositivo actual:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función generadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(\n",
    "    model_checkpoint_path,\n",
    "    title,\n",
    "    artist,\n",
    "    lyrics_start=\"\",\n",
    "    max_length=150,\n",
    "    temperature=1.0,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "):\n",
    "    # Cargar tokenizer y modelo\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2-medium\")\n",
    "    tokenizer.add_special_tokens({\n",
    "        \"additional_special_tokens\": [\"<|endoflyric|>\"],\n",
    "        \"pad_token\": \"<|pad|>\"\n",
    "    })\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_checkpoint_path)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Construir el prompt\n",
    "    prompt = f\"[Artista: {artist}]\\n[Canción: {title}]\\n{lyrics_start}\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generación\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.convert_tokens_to_ids(\"<|endoflyric|>\")\n",
    "    )\n",
    "\n",
    "    # Decodificar\n",
    "    generated = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Artista: Muse]\n",
      "[Canción: Unintended]\n",
      "You could be my unintended baby\n",
      "I've learned to keep my distance\n",
      "But I see you're still there\n",
      "\n",
      "You’ll be my unexpected baby\n",
      "And you've done it before\n",
      "We all know that it can't last forever\n",
      "\n",
      "You’ll be my unexpected baby\n",
      "And you’ve done it before\n",
      "We all know that it can't last forever\n",
      "\n",
      "I can't say it\n",
      "So I will just say it\n",
      "\n",
      "I can't say it\n",
      "So I will just say it\n",
      "I can't say it\n",
      "So I will just say it\n",
      "\n",
      "I'm still going to hurt you\n",
      "I am, I am\n",
      "And I’ll stay that way\n",
      "But we'll get back to the truth\n",
      "(And I’m still going to hurt you)\n",
      "And you’ll find a way to turn that around\n",
      "So I will just\n"
     ]
    }
   ],
   "source": [
    "rock_model_path = \"./lyrics_generator_rock/checkpoint-1000\"\n",
    "\n",
    "generated_rock_lyrics = generate_lyrics(\n",
    "    model_checkpoint_path=rock_model_path,\n",
    "    title=\"Unintended\",\n",
    "    artist=\"Muse\",\n",
    "    lyrics_start=\"You could be my unintended\",\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "print(generated_rock_lyrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
